{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anyhann/EjerciciosAndroid/blob/master/Python__Biblioteca_Limpieza_Datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creacion de una biblioteca** personalizada de Python para limpieza de datos :\n",
        "1. Crea una nueva carpeta para tu biblioteca, por ejemplo, data_cleaning_library.\n",
        "2. Dentro de esta carpeta, crea un archivo vacío llamado __init__.py. Este archivo le indica a Python que la carpeta debe tratarse como un paquete.\n",
        "3. Crea un archivo Python para definir tus funciones de limpieza, por ejemplo, cleaning_functions.py. En este archivo, puedes definir diferentes funciones para limpiar y dar formato a tus datos.\n",
        "\n",
        "Aquí hay algunos ejemplos de funciones de limpieza que puedes incluir en tu biblioteca:"
      ],
      "metadata": {
        "id": "OCmwYFWl9TYh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H-acXq29Quf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def eliminar_duplicados(df):\n",
        "    \"\"\"\n",
        "    Elimina filas duplicadas de un DataFrame de pandas.\n",
        "    \"\"\"\n",
        "    return df.drop_duplicates()\n",
        "\n",
        "def eliminar_valores_faltantes(df, umbral):\n",
        "    \"\"\"\n",
        "    Elimina las columnas con un porcentaje de valores faltantes mayor al umbral especificado.\n",
        "    \"\"\"\n",
        "    proporcion_valores_faltantes = df.isnull().mean()\n",
        "    columnas_a_eliminar = proporcion_valores_faltantes[proporcion_valores_faltantes > umbral].index\n",
        "    return df.drop(columnas_a_eliminar, axis=1)\n",
        "\n",
        "def rellenar_valores_faltantes(df, metodo='media'):\n",
        "    \"\"\"\n",
        "    Rellena los valores faltantes utilizando el método especificado ('media', 'mediana' o 'moda').\n",
        "    \"\"\"\n",
        "    if metodo == 'media':\n",
        "        return df.fillna(df.mean())\n",
        "    elif metodo == 'mediana':\n",
        "        return df.fillna(df.median())\n",
        "    elif metodo == 'moda':\n",
        "        return df.fillna(df.mode().iloc[0])\n",
        "    else:\n",
        "        raise ValueError(\"El método especificado no es válido. Usa 'media', 'mediana' o 'moda'.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def convertir_a_minusculas(df, columnas):\n",
        "    \"\"\"\n",
        "    Convierte el texto en las columnas especificadas a minúsculas.\n",
        "    \"\"\"\n",
        "    for col in columnas:\n",
        "        df[col] = df[col].str.lower()\n",
        "    return df\n",
        "\n",
        "def eliminar_caracteres_especiales(df, columnas):\n",
        "    \"\"\"\n",
        "    Elimina los caracteres especiales de las columnas especificadas.\n",
        "    \"\"\"\n",
        "    for col in columnas:\n",
        "        df[col] = df[col].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
        "    return df\n",
        "\n",
        "def convertir_a_fecha(df, columnas, formato):\n",
        "    \"\"\"\n",
        "    Convierte las columnas especificadas a formato de fecha.\n",
        "    \"\"\"\n",
        "    for col in columnas:\n",
        "        df[col] = pd.to_datetime(df[col], format=formato)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "s9lt0JGmAJyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def eliminar_espacios_en_blanco(df, columnas):\n",
        "    \"\"\"\n",
        "    Elimina los espacios en blanco al principio y al final de las cadenas de texto en las columnas especificadas.\n",
        "    \"\"\"\n",
        "    for col in columnas:\n",
        "        df[col] = df[col].str.strip()\n",
        "    return df\n",
        "\n",
        "def eliminar_outliers(df, columnas, umbral):\n",
        "    \"\"\"\n",
        "    Elimina los valores atípicos (outliers) de las columnas especificadas utilizando el método del rango intercuartil (IQR).\n",
        "    \"\"\"\n",
        "    for col in columnas:\n",
        "        q1 = df[col].quantile(0.25)\n",
        "        q3 = df[col].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - umbral * iqr\n",
        "        upper_bound = q3 + umbral * iqr\n",
        "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "    return df\n",
        "\n",
        "def codificar_categorias(df, columnas):\n",
        "    \"\"\"\n",
        "    Codifica las categorías en las columnas especificadas utilizando la técnica de one-hot encoding.\n",
        "    \"\"\"\n",
        "    for col in columnas:\n",
        "        df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
        "        df = df.drop(col, axis=1)\n",
        "    return df"
      ],
      "metadata": {
        "id": "iR88FxYgAiH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "def eliminar_palabras_vacias(df, columnas):\n",
        "    \"\"\"\n",
        "    Elimina las palabras vacías (stop words) de las columnas especificadas.\n",
        "    \"\"\"\n",
        "    from nltk.corpus import stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    for col in columnas:\n",
        "        df[col] = df[col].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
        "    return df\n",
        "\n",
        "def normalizar_texto(df, columnas):\n",
        "    \"\"\"\n",
        "    Normaliza el texto en las columnas especificadas eliminando acentos y caracteres especiales.\n",
        "    \"\"\"\n",
        "    import unicodedata\n",
        "    for col in columnas:\n",
        "        df[col] = df[col].apply(lambda x: unicodedata.normalize('NFKD', x).encode('ASCII', 'ignore').decode('utf-8'))\n",
        "    return df\n",
        "\n",
        "def discretizar_columna(df, columna, bins):\n",
        "    \"\"\"\n",
        "    Discretiza una columna numérica en intervalos especificados por el usuario.\n",
        "    \"\"\"\n",
        "    df[columna] = pd.cut(df[columna], bins=bins, labels=False)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "HF3JuefhBMJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que hayas definido tus funciones de limpieza, puedes importarlas y utilizarlas en tus proyectos. Por ejemplo, si tienes un archivo main.py en la misma carpeta que tu carpeta data_cleaning_library, puedes usarlo de la siguiente manera:\n"
      ],
      "metadata": {
        "id": "9AuN27qg-6Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from data_cleaning_library.cleaning_functions import eliminar_duplicados, eliminar_valores_faltantes, rellenar_valores_faltantes\n",
        "\n",
        "# Cargar los datos\n",
        "datos = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Usar las funciones de limpieza\n",
        "datos = eliminar_duplicados(datos)\n",
        "datos = eliminar_valores_faltantes(datos, umbral=0.5)\n",
        "datos = rellenar_valores_faltantes(datos, metodo='media')\n",
        "\n",
        "\n",
        "# Continuar con el análisis de datos\n"
      ],
      "metadata": {
        "id": "dqWq0jlh-8XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalzacion de Datos / Escala de Datos**\n",
        "La librería sklearn tiene un módulo de pre-procesamiento (preprocessing) para implementar métodos de escalado estándar. El StandardScalar se muestra a continuación. Cada columna se normaliza a una media cero y una desviación estándar de uno. Los métodos de escalado comunes fit_transform(X) para ajuste y transform(X) transformación basado en otro ajuste, y inverse_transform(Xs) para volver a escalar a la representación original."
      ],
      "metadata": {
        "id": "IVjlHuaf_Y2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def transformar_datos(datos):\n",
        "    scaler = StandardScaler()\n",
        "    ds = scaler.fit_transform(datos)\n",
        "    #El valor ds se devuelve como un array numpy así que tenemos que convertirlo de nuevo a pandas DataFrame, \n",
        "    #reutilizando los nombres de columna datos.\n",
        "    ds = pd.DataFrame(ds, columns=datos.columns)\n",
        "    return ds.head()"
      ],
      "metadata": {
        "id": "-sXcbtr2_gDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzyvvtba_-66",
        "outputId": "ebb9e876-e696-4508-b786-a8289f1b72f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**No dudes en agregar otras funciones de limpieza y formato según tus necesidades específicas.**"
      ],
      "metadata": {
        "id": "pc8e70Zm_Y24"
      }
    }
  ]
}